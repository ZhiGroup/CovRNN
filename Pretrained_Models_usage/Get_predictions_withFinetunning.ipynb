{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Tools and Packages\n",
    "##Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, random\n",
    "import math\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "## ML and Stats \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as m\n",
    "import sklearn.linear_model  as lm\n",
    "import lifelines#.estimation import KaplanMeierFitter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import export_graphviz\n",
    "import statsmodels.formula.api as sm\n",
    "import patsy\n",
    "from scipy import stats\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "## Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "%matplotlib inline\n",
    "import plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "from IPython.display import HTML\n",
    "\n",
    "## DL Framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "###GPU enabling and device allocation\n",
    "use_cuda = torch.cuda.is_available()\n",
    "#torch.cuda.set_device(1) ## uncomment if you need to specify specific GPU\n",
    "\n",
    "#use_cuda=False ## uncomment if you need explicitly to not use GPU\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "### import pytorch ehr files\n",
    "#import sys\n",
    "#sys.path.insert(0, '../ehr_pytorch')\n",
    "\n",
    "import pytorch_ehr_3.models as model \n",
    "from pytorch_ehr_3.EHRDataloader import EHRdataloader\n",
    "from pytorch_ehr_3.EHRDataloader import EHRdataFromLoadedPickles as EHRDataset\n",
    "import pytorch_ehr_3.utils as ut \n",
    "from pytorch_ehr_3.EHREmb import EHREmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Read the header of data_preprocess_v5.py for more information\n",
    "\n",
    "!python data_preprocess_v5.py data_tab_delimited.txt label_tab_delimited.txt medicalcode_mapping_to_token_file.types output_folder/file_prefix NA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### load Data\n",
    "train_sl= pickle.load(open('output_folder/file_prefix.combined.train', 'rb'), encoding='bytes')\n",
    "valid_sl= pickle.load(open('output_folder/file_prefix.combined.valid', 'rb'), encoding='bytes')\n",
    "test_sl= pickle.load(open('output_folder/file_prefix.combined.test', 'rb'), encoding='bytes')\n",
    "\n",
    "types_d=pickle.load(open('output_folder/file_prefix.types', 'rb'), encoding='bytes')\n",
    "types_d_rev = dict(zip(types_d.values(),types_d.keys()))\n",
    "new_input_size=max(types_d_rev.keys())+1\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Sometimes, if you face a memory issue, it can be due to some exceptional patients who had pretty very rich history\n",
    "## so you may need to exclude those during the fine-tuning, using some statement like:\n",
    "\n",
    "train_sl_n=[]\n",
    "for x in train_sl:\n",
    "       if len(x[-1])<1000 & (len(max(x[-1], key=lambda xmb: len(xmb[1]))[1]))<1000 : train_sl_n.append(x)\n",
    "\n",
    "# and make sure you replace any train_sl below, with the new train_sl_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Models Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load our models\n",
    "## Based on the pytorch version, you may face an error loading the model directly using torch.load,\n",
    "## therefore added the except section to initiate the model and then populate the paramters from the state dictionary\n",
    "try:\n",
    "    mort_model = torch.load('CRWD_Pretrained_Models/CovRNN_iMort_v552.pth')\n",
    "    vent_model = torch.load('CRWD_Pretrained_Models/CovRNN_mVent_v552.pth')\n",
    "    plos_model = torch.load('CRWD_Pretrained_Models/CovRNN_pLOS_v552.pth')\n",
    "    mort_surv_model = torch.load('CRWD_Pretrained_Models/CovRNN_iMort_Surv_v552.pth')\n",
    "    vent_surv_model = torch.load('CRWD_Pretrained_Models/CovRNN_mVent_Surv_v552.pth')\n",
    "    \n",
    "except:\n",
    "    mort_model = model.EHR_RNN([123641], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True )\n",
    "    mort_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_iMort_v552.st'))\n",
    "\n",
    "    vent_model = model.EHR_RNN([123641], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True )\n",
    "    vent_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_mVent_v552.st'))\n",
    "\n",
    "    plos_model = model.EHR_RNN([123641], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True )\n",
    "    plos_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_pLOS_v552.st'))\n",
    "\n",
    "    mort_surv_model = model.EHR_RNN([123641], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
    "    mort_surv_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_iMort_Surv_v552.st'))\n",
    "\n",
    "    vent_surv_model = model.EHR_RNN([123641], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
    "    vent_surv_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_mVent_Surv_v552.st'))\n",
    "\n",
    "\n",
    "#### For fine-tuning and as we will add new vocab to the embedding layer\n",
    "\n",
    "mort_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123641, loaded_ehr_model.embed_dim))))\n",
    "vent_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123641, loaded_ehr_model.embed_dim))))\n",
    "plos_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123641, loaded_ehr_model.embed_dim))))\n",
    "mort_surv_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123641, loaded_ehr_model.embed_dim))))\n",
    "vent_surv_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123641, loaded_ehr_model.embed_dim))))\n",
    "\n",
    "    \n",
    "if use_cuda:\n",
    "    mort_model.cuda()\n",
    "    vent_model.cuda()\n",
    "    plos_model.cuda()\n",
    "    vent_surv_model.cuda()\n",
    "    mort_surv_model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fine_tune_utils as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[train_mbs,valid_mbs,test_mbs]=ft.load_mbs_var([train_sl, valid_sl,test_sl],packpadmode=True,bs=128)\n",
    "\n",
    "train_auc_allep_m,valid_auc_allep_m,test_auc_allep_m,RNN_f_label_m,RNN_f_score_m=run_dl_model(mort_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_mort_finetuned.pth','CovRNN_mort_finetuned.st',wmodel='RNN',packpadmode=True,task='mort')\n",
    "train_auc_allep_v,valid_auc_allep_v,test_auc_allep_v,RNN_f_label_v,RNN_f_score_v=run_dl_model(vent_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_vent_finetuned.pth','CovRNN_vent_finetuned.st',wmodel='RNN',packpadmode=True,task='vent')\n",
    "train_auc_allep_p,valid_auc_allep_p,test_auc_allep_p,RNN_f_label_p,RNN_f_score_p=run_dl_model(plos_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_plos_finetuned.pth','CovRNN_plos_finetuned.st',wmodel='RNN',packpadmode=True,task='plos')\n",
    "train_auc_allep_ms,valid_auc_allep_ms,test_auc_allep_ms,RNN_f_label_ms,RNN_f_score_ms=run_dl_model_surv(mort_surv_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_mort_surv_finetuned.pth','CovRNN_mort_surv_finetuned.st',wmodel='RNN',packpadmode=True,task='mort_surv')\n",
    "train_auc_allep_vs,valid_auc_allep_vs,test_auc_allep_vs,RNN_f_label_vs,RNN_f_score_vs=run_dl_model_surv(vent_surv_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_vent_surv_finetuned.pth','CovRNN_vent_surv_finetuned.st',wmodel='RNN',packpadmode=True,task='vent_surv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Although you can use the RNN_f_label_x created above as the true label and the RNN_f_score_x as the predicted score\n",
    "## you can also run pt_predictions in a similar way \n",
    "mort_model_finetuned = torch.load('CovRNN_mort_finetuned.pth')\n",
    "vent_model_finetuned = torch.load('CovRNN_vent_finetuned.pth')\n",
    "plos_model_finetuned = torch.load('CovRNN_plos_finetuned.pth')\n",
    "mort_surv_model_finetuned = torch.load('CovRNN_mort_surv_finetuned.pth')\n",
    "vent_surv_model_finetuned = torch.load('CovRNN_vent_surv_finetuned.pth')\n",
    "\n",
    "mort_model_finetuned.eval()\n",
    "vent_model_finetuned.eval()\n",
    "plos_model_finetuned.eval()\n",
    "vent_surv_model_finetuned.eval()\n",
    "mort_surv_model_finetuned.eval()\n",
    "\n",
    "newData_preds_afterFinetune=ft.pt_predictions(test_sl,mort_model_finetuned,mort_surv_model_finetuned,vent_model_finetuned\n",
    "                                ,vent_surv_model_finetuned,plos_model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newData_preds_afterFinetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newData_preds_afterFinetune.to_csv('newData_preds_afterFinetune_v1.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
