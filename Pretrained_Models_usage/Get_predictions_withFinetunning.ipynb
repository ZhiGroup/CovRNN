{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "py37",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Get_predictions_withFinetunning.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9LkYXLWhg0h"
      },
      "source": [
        "The first 3 cells are for Colab use only: get access to drive, unzip the repo and install packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iy0CdQse6zm"
      },
      "source": [
        "## Uncomment if using google colab\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlWYMU-VhmPI"
      },
      "source": [
        "## Download zip file from Github and unzip in google colab\n",
        "#import zipfile\n",
        "#with zipfile.ZipFile(\"CovRNN-main.zip\",\"r\") as zip_ref:\n",
        "#    zip_ref.extractall(\"CovRNN-test\")\n",
        "\n",
        "#%cd drive/My Drive/Colab Notebooks/CovRNN-test/CovRNN-main/Pretrained_Models_usage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUm_4gVSRt3D"
      },
      "source": [
        "## Install required packages on colab\n",
        "#! pip install lifelines\n",
        "#! pip install statsmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KidA8B6fRfwj",
        "collapsed": true
      },
      "source": [
        "### Tools and Packages\n",
        "##Basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys, random\n",
        "import math\n",
        "try:\n",
        "    import cPickle as pickle\n",
        "except:\n",
        "    import pickle\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "## ML and Stats \n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics as m\n",
        "import sklearn.linear_model  as lm\n",
        "import lifelines#.estimation import KaplanMeierFitter\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.tree import export_graphviz\n",
        "import statsmodels.formula.api as sm\n",
        "import patsy\n",
        "from scipy import stats\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "## Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "%matplotlib inline\n",
        "import plotly as py\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "import plotly.tools as tls\n",
        "import plotly.graph_objs as go\n",
        "from plotly.graph_objs import *\n",
        "from IPython.display import HTML\n",
        "\n",
        "## DL Framework\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "###GPU enabling and device allocation\n",
        "use_cuda = torch.cuda.is_available()\n",
        "#torch.cuda.set_device(1) ## uncomment if you need to specify specific GPU\n",
        "\n",
        "#use_cuda=False ## uncomment if you need explicitly to not use GPU\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "### import pytorch ehr files\n",
        "#import sys\n",
        "#sys.path.insert(0, '../ehr_pytorch')\n",
        "\n",
        "import pytorch_ehr_3.models as model \n",
        "from pytorch_ehr_3.EHRDataloader import EHRdataloader\n",
        "from pytorch_ehr_3.EHRDataloader import EHRdataFromLoadedPickles as EHRDataset\n",
        "import pytorch_ehr_3.utils as ut \n",
        "from pytorch_ehr_3.EHREmb import EHREmbeddings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I5xGgcbRfwp"
      },
      "source": [
        "### Data Prepartion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qNfqMU-WRfwr"
      },
      "source": [
        "### Read the header of data_preprocess_v5.py for more information\n",
        "\n",
        "!python data_preprocess_v5.py sample_data.txt sample_label.txt CRWD_Pretrained_Models/lr_inhosp_outcome_pred_v1.types output_folder/file_prefix NA\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srovOevwRfws"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPM13n2kRfwt"
      },
      "source": [
        "### load Data\n",
        "train_sl= pickle.load(open('output_folder/file_prefix.combined.train', 'rb'), encoding='bytes')\n",
        "valid_sl= pickle.load(open('output_folder/file_prefix.combined.valid', 'rb'), encoding='bytes')\n",
        "test_sl= pickle.load(open('output_folder/file_prefix.combined.test', 'rb'), encoding='bytes')\n",
        "\n",
        "types_d=pickle.load(open('output_folder/file_prefix.types', 'rb'), encoding='bytes')\n",
        "types_d_rev = dict(zip(types_d.values(),types_d.keys()))\n",
        "new_input_size=max(types_d_rev.keys())+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-vAPUkiDShz"
      },
      "source": [
        "#### Sometimes, if you face a memory issue, it can be due to some exceptional patients who had pretty very rich history\n",
        "## so you may need to exclude those during the fine-tuning, using some statement like:\n",
        "\n",
        "#train_sl_n=[]\n",
        "#for x in train_sl:\n",
        "#       if len(x[-1])<1000 & (len(max(x[-1], key=lambda xmb: len(xmb[1]))[1]))<1000 : train_sl_n.append(x)\n",
        "\n",
        "## and make sure you replace any train_sl below, with the new train_sl_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwCn51yqRfwv"
      },
      "source": [
        "### Pretrained Models Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Ls8PBFRfww"
      },
      "source": [
        "### Load our models\n",
        "## Based on the pytorch version, you may face an error loading the model directly using torch.load,\n",
        "## therefore added the except section to initiate the model and then populate the paramters from the state dictionary\n",
        "try:\n",
        "    mort_model = torch.load('CRWD_Pretrained_Models/CovRNN_iMort_v552.pth')\n",
        "    vent_model = torch.load('CRWD_Pretrained_Models/CovRNN_mVent_v552.pth')\n",
        "    plos_model = torch.load('CRWD_Pretrained_Models/CovRNN_pLOS_v552.pth')\n",
        "    mort_surv_model = torch.load('CRWD_Pretrained_Models/CovRNN_iMort_Surv_v552.pth')\n",
        "    vent_surv_model = torch.load('CRWD_Pretrained_Models/CovRNN_mVent_Surv_v552.pth')\n",
        "    \n",
        "except:\n",
        "    mort_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True )\n",
        "    mort_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_iMort_v552.st'))\n",
        "\n",
        "    vent_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True )\n",
        "    vent_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_mVent_v552.st'))\n",
        "\n",
        "    plos_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True )\n",
        "    plos_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_pLOS_v552.st'))\n",
        "\n",
        "    mort_surv_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    mort_surv_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_iMort_Surv_v552.st'))\n",
        "\n",
        "    vent_surv_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    vent_surv_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_mVent_Surv_v552.st'))\n",
        "\n",
        "\n",
        "#### For fine-tuning and as we will add new vocab to the embedding layer\n",
        "\n",
        "mort_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123642, mort_model.embed_dim))))\n",
        "vent_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123642, vent_model.embed_dim))))\n",
        "plos_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123642, plos_model.embed_dim))))\n",
        "mort_surv_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123642, mort_surv_model.embed_dim))))\n",
        "vent_surv_model.embed.weight = nn.Parameter(torch.cat((mort_model.embed.weight, torch.zeros(new_input_size-123642, vent_surv_model.embed_dim))))\n",
        "\n",
        "    \n",
        "if use_cuda:\n",
        "    mort_model.cuda()\n",
        "    vent_model.cuda()\n",
        "    plos_model.cuda()\n",
        "    vent_surv_model.cuda()\n",
        "    mort_surv_model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omm9rwwPRfwy"
      },
      "source": [
        "### Model Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2j5WpEH9Rfwy"
      },
      "source": [
        "import fine_tune_utils as ft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ahFW3_HkRfwz"
      },
      "source": [
        "[train_mbs,valid_mbs,test_mbs]=ft.load_mbs_var([train_sl, valid_sl,test_sl],packpadmode=True,bs=128)\n",
        "\n",
        "train_auc_allep_m,valid_auc_allep_m,test_auc_allep_m,RNN_f_label_m,RNN_f_score_m=ft.run_dl_model(mort_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_mort_finetuned.pth','CovRNN_mort_finetuned.st',wmodel='RNN',packpadmode=True,task='mort')\n",
        "train_auc_allep_v,valid_auc_allep_v,test_auc_allep_v,RNN_f_label_v,RNN_f_score_v=ft.run_dl_model(vent_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_vent_finetuned.pth','CovRNN_vent_finetuned.st',wmodel='RNN',packpadmode=True,task='vent')\n",
        "train_auc_allep_p,valid_auc_allep_p,test_auc_allep_p,RNN_f_label_p,RNN_f_score_p=ft.run_dl_model(plos_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_plos_finetuned.pth','CovRNN_plos_finetuned.st',wmodel='RNN',packpadmode=True,task='plos')\n",
        "train_auc_allep_ms,valid_auc_allep_ms,test_auc_allep_ms,RNN_f_label_ms,RNN_f_score_ms=ft.run_dl_model_surv(mort_surv_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_mort_surv_finetuned.pth','CovRNN_mort_surv_finetuned.st',wmodel='RNN',packpadmode=True,task='mort_surv')\n",
        "train_auc_allep_vs,valid_auc_allep_vs,test_auc_allep_vs,RNN_f_label_vs,RNN_f_score_vs=ft.run_dl_model_surv(vent_surv_model,train_mbs,valid_mbs,[test_mbs],'CovRNN_vent_surv_finetuned.pth','CovRNN_vent_surv_finetuned.st',wmodel='RNN',packpadmode=True,task='vent_surv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CBYZVubERfw0"
      },
      "source": [
        "## Although you can use the RNN_f_label_x created above as the true label and the RNN_f_score_x as the predicted score\n",
        "## you can also run pt_predictions in a similar way \n",
        "mort_model_finetuned = torch.load('CovRNN_mort_finetuned.pth')\n",
        "vent_model_finetuned = torch.load('CovRNN_vent_finetuned.pth')\n",
        "plos_model_finetuned = torch.load('CovRNN_plos_finetuned.pth')\n",
        "mort_surv_model_finetuned = torch.load('CovRNN_mort_surv_finetuned.pth')\n",
        "vent_surv_model_finetuned = torch.load('CovRNN_vent_surv_finetuned.pth')\n",
        "\n",
        "mort_model_finetuned.eval()\n",
        "vent_model_finetuned.eval()\n",
        "plos_model_finetuned.eval()\n",
        "vent_surv_model_finetuned.eval()\n",
        "mort_surv_model_finetuned.eval()\n",
        "\n",
        "newData_preds_afterFinetune=ft.pt_predictions(test_sl,mort_model_finetuned,mort_surv_model_finetuned,vent_model_finetuned\n",
        "                                ,vent_surv_model_finetuned,plos_model_finetuned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Pm9YSv-YRfw0"
      },
      "source": [
        "newData_preds_afterFinetune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "k6VUrqegRfw1"
      },
      "source": [
        "newData_preds_afterFinetune.to_csv('newData_preds_afterFinetune_v1.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}