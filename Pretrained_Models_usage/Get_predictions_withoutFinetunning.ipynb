{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "py37",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Get_predictions_withoutFinetunning.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TI4j_V7KTLu"
      },
      "source": [
        "The first 3 cells are for Colab use only: get access to drive, unzip the repo and install packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDV75V20KW_l"
      },
      "source": [
        "## Uncomment if using google colab\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc6WDBEUKXYF"
      },
      "source": [
        "## Download zip file from Github and unzip in google colab\n",
        "#import zipfile\n",
        "#with zipfile.ZipFile(\"CovRNN-main.zip\",\"r\") as zip_ref:\n",
        "#    zip_ref.extractall(\"CovRNN-test\")\n",
        "\n",
        "#%cd drive/My Drive/Colab Notebooks/CovRNN-test/CovRNN-main/Pretrained_Models_usage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiColsh4KXbi"
      },
      "source": [
        "## Install required packages on colab\n",
        "#! pip install lifelines\n",
        "#! pip install statsmodels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlPtmTuF3WTp"
      },
      "source": [
        "### Tools and Packages\n",
        "##Basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys, random\n",
        "import math\n",
        "try:\n",
        "    import cPickle as pickle\n",
        "except:\n",
        "    import pickle\n",
        "import string\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "## ML and Stats \n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics as m\n",
        "import sklearn.linear_model  as lm\n",
        "import lifelines\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.tree import export_graphviz\n",
        "import statsmodels.formula.api as sm\n",
        "import patsy\n",
        "from scipy import stats\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "## Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "%matplotlib inline\n",
        "import plotly as py\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "import plotly.tools as tls\n",
        "import plotly.graph_objs as go\n",
        "from plotly.graph_objs import *\n",
        "from IPython.display import HTML\n",
        "\n",
        "## DL Framework\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "\n",
        "###GPU enabling and device allocation\n",
        "use_cuda = torch.cuda.is_available()\n",
        "#torch.cuda.set_device(1) ## uncomment if you need to specify specific GPU\n",
        "\n",
        "#use_cuda=False ## uncomment if you need explicitly to not use GPU\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "### import pytorch ehr files\n",
        "#import sys\n",
        "#sys.path.insert(0, '../ehr_pytorch')\n",
        "\n",
        "import pytorch_ehr_3.models as model \n",
        "from pytorch_ehr_3.EHRDataloader import EHRdataloader\n",
        "from pytorch_ehr_3.EHRDataloader import EHRdataFromLoadedPickles as EHRDataset\n",
        "import pytorch_ehr_3.utils as ut \n",
        "from pytorch_ehr_3.EHREmb import EHREmbeddings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9UJgV3K3WTt"
      },
      "source": [
        "### Data Prepartion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztgSsnvX3WTw"
      },
      "source": [
        "### Read the header of data_preprocess_v4.py for more information\n",
        "\n",
        "!python data_preprocess_v5.py sample_data.txt sample_label.txt CRWD_Pretrained_Models/lr_inhosp_outcome_pred_v1.types output_withoutFT/file_prefix nosplit\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e44S8mpy3WTx"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9BqGZjE3WTy"
      },
      "source": [
        "### load Data\n",
        "test_sl= pickle.load(open('output_withoutFT/file_prefix.combined.all', 'rb'), encoding='bytes')\n",
        "len(test_sl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DbjLr23y3WTy"
      },
      "source": [
        "#### In order to avoid any errors from patients who had new medical codes, that were not used during the pretraining\n",
        "## you may need to exclude those patients from your test set, using some statement like:\n",
        "\n",
        "test_sl_n=[]\n",
        "for x in test_sl:\n",
        "       if (max(max(x[-1], key=lambda xmb: max(xmb[1]))[1]))<123642 : test_sl_n.append(x)\n",
        "        \n",
        "### make sure, that you replace all test_sl below with the new test_sl_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rnFZJyl3WTz"
      },
      "source": [
        "### Load our models\n",
        "## Based on the pytorch version, you may face an error loading the model directly using torch.load,\n",
        "## therefore added the except section to initiate the model and then populate the paramters from the state dictionary\n",
        "try:\n",
        "    mort_model = torch.load('CRWD_Pretrained_Models/CovRNN_iMort_v552.pth')\n",
        "    vent_model = torch.load('CRWD_Pretrained_Models/CovRNN_mVent_v552.pth')\n",
        "    plos_model = torch.load('CRWD_Pretrained_Models/CovRNN_pLOS_v552.pth')\n",
        "    mort_surv_model = torch.load('CRWD_Pretrained_Models/CovRNN_iMort_Surv_v552.pth')\n",
        "    vent_surv_model = torch.load('CRWD_Pretrained_Models/CovRNN_mVent_Surv_v552.pth')\n",
        "    \n",
        "except:\n",
        "    mort_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    mort_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_iMort_v552.st'))\n",
        "\n",
        "    vent_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    vent_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_mVent_v552.st'))\n",
        "\n",
        "    plos_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    plos_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_pLOS_v552.st'))\n",
        "\n",
        "    mort_surv_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    mort_surv_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_iMort_Surv_v552.st'))\n",
        "\n",
        "    vent_surv_model = model.EHR_RNN([123642], embed_dim=64, hidden_size=64, n_layers=1, dropout_r=0., cell_type='GRU', bii=False , time=True , surv=True)\n",
        "    vent_surv_model.load_state_dict(torch.load('CRWD_Pretrained_Models/state_dicts/CovRNN_mVent_Surv_v552.st'))\n",
        "\n",
        "\n",
        "if use_cuda:\n",
        "    mort_model.cuda()\n",
        "    vent_model.cuda()\n",
        "    plos_model.cuda()\n",
        "    vent_surv_model.cuda()\n",
        "    mort_surv_model.cuda()\n",
        "\n",
        "mort_model.eval()\n",
        "vent_model.eval()\n",
        "plos_model.eval()\n",
        "vent_surv_model.eval()\n",
        "mort_surv_model.eval()\n",
        "\n",
        "def pt_predictions(test_set):\n",
        "    with torch.no_grad():\n",
        "        pt_preds=[]\n",
        "        for pt in test_set:\n",
        "            #print(pt)\n",
        "            pt_id=pt[0]\n",
        "            pt_ds = EHRDataset([pt],sort= True, model='RNN')\n",
        "            #print(pt_ds)\n",
        "            pt_m = list(EHRdataloader(pt_ds, batch_size = 1, packPadMode = True,multilbl=True))\n",
        "            #print(len(pt_m[0]))\n",
        "            x1, label,seq_len,time_diff = pt_m[0]\n",
        "            if use_cuda:\n",
        "                label=label.cpu().squeeze().numpy()          \n",
        "                mort_score = mort_model(x1,seq_len,time_diff).cpu().numpy()\n",
        "                mort_surv_score = mort_surv_model(x1,seq_len,time_diff).cpu().numpy()\n",
        "                vent_score = vent_model(x1,seq_len,time_diff).cpu().numpy()\n",
        "                vent_surv_score = vent_surv_model(x1,seq_len,time_diff).cpu().numpy()\n",
        "                plos_score = plos_model(x1,seq_len,time_diff).cpu().numpy()\n",
        "            else:  \n",
        "                label=label.squeeze().numpy()\n",
        "                mort_score = mort_model(x1,seq_len,time_diff).numpy()\n",
        "                mort_surv_score = mort_surv_model(x1,seq_len,time_diff).numpy()\n",
        "                vent_score = vent_model(x1,seq_len,time_diff).numpy()\n",
        "                vent_surv_score = vent_surv_model(x1,seq_len,time_diff).numpy()\n",
        "                plos_score = plos_model(x1,seq_len,time_diff).numpy()\n",
        "            pt_preds.append([pt_id,label[0],label[1],mort_score,mort_surv_score,label[2],label[3],vent_score,vent_surv_score,label[5],plos_score])\n",
        "    \n",
        "    pt_preds_df= pd.DataFrame(pt_preds)\n",
        "    pt_preds_df.columns=['pt','mort_label','mort_tte','mort_prob','mort_logHF','vent_label','vent_tte','vent_prob','vent_logHF','plos_label','plos_prob']\n",
        "    return pt_preds_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fmmRKbRP3WT2"
      },
      "source": [
        "newData_preds=pt_predictions(test_sl_n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8VfBwT-3WT3"
      },
      "source": [
        "newData_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "oA3bYXtc3WT4"
      },
      "source": [
        "newData_preds.to_csv('newData_preds_v1.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5dXhu2HQ3WT4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}